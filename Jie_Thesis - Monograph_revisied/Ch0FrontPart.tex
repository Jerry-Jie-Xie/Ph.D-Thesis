% Part0FrontPart.tex

%============frontmatter % Coverpage etc
\title{Acoustic classification of Australian frogs for ecosystem surveys}
       
\author{Jie Xie}
%\authoremail{xiej8734@gmail.com}
\supervisor{Dr Jinglan Zhang, Professor Paul Roe, Dr Michael Towsey, Professor Vinold Chandran}
\thesistype{Doctor of Philosophy}    % or comment it out (the default is Doctor of Philosophy)
\university{Queensland University of Technology} % or comment it out (the default is QUT)
\faculty{Science and Engineering Faculty}   % or comment it out (the default one is SEF)
\school{School of Electrical Engineering and Computer Science}   % or School of xxx xxx xxx 
                         % or comment it out (the default one is Elec Eng and Computer Science)                         
%\universitylogo{yes}{1.0}{./QUTLogo.eps}  % yes (true, 1) or no (false, 0), scale = 1.0; filename = QUTLogo.eps

%

\submissiondate{August 2016}
\copyrightyear{2016}
%\informationcutoffdate{01 March 2010} %for cut of date of information in the thesis

\maketitle	   %cover page of the thesis; a blank page is automatically added for double-side printing

%\blankpage         %two more blank pages. If you don't want them, comment them out
% \blankpage

\setcounter{page}{1} %start to count page numbers

% \insidetitlepage   %if you don't like an insidetitle page, comment it out

\copyrightpage     %another format available: \copyrightpageWithTitle. You may try it (with thesis title). 

%\signaturepage\cleardoublepage   % you may not need this signature page, so comment it out

%============dedication
\begin{dedication}
To my family 
\end{dedication}

%============abstract
\begin{abstract}
Frogs play an important role in the Earth's ecosystem, 
but the decline of their population has been spotted from locations around the world. Monitoring frog activity can assist conservation efforts, and improve our understanding of their interactions with the environment and other organisms. Traditional observation methods require ecologists and volunteers to visit the field, which greatly limit the scale for acoustic data collection. Recent advances in acoustic sensors provide a novel method to survey vocalising animals such as frogs. Once sensors are successfully installed in the field, acoustic data can be automatically collected at large spatial and temporal scales. For each acoustic sensor, 
several gigabytes of compressed audio data can be generated per day, and thus large volumes of raw acoustic data have been collected. To gain insights about frogs and the environment, classifying frog species in acoustic data is necessary. However, manual species identification is unfeasible due to the amount of collected data, and enabling automated species classification has become very important. Most previous studies on machine learning for frog call classification often have two limitations: (1) frog recordings often have a high SNR ($\geq$ 15 dB); (2) each individual recording is assumed to contain only one frog species. However, field recordings typically have a low SNR ($<$ 15 dB) and contain multiple simultaneously vocalising frog species. 
This thesis aims to address those two limitations, and has the following contributions.

\begin{enumerate} 
\item[(1)] Develop a fused feature set from temporal, perceptual, and cepstral domains for improving the state-of-the-art performance of frog call classification using trophy recordings (Chapter~\ref{cha:cha4EnhancedFeature}). 
\\
Various acoustic features have been developed to classify frog calls, which can be generally categorised into three types: temporal feature, perceptual feature, and cepstral feature. Most previous studies often use features from one domain or two domains, which cannot effectively classify 
those frog species that share similar acoustic attributes in one or two domains for the classification. In this chapter, a novel fusion of temporal, perceptual, and cepstral features is proposed, so that those frog species, which share similar acoustic attributes in one or two domains, can be successfully classified.
An intensive analysis shows that our fused feature set consistently outperforms the state-of-the-art features for frog call classification using trophy recordings.


\item[(2)]	Propose a novel cepstral feature based on adaptive frequency scaled WPD to classify frog calls using both trophy and field recordings (Chapter~\ref{cha:cha5WaveletFeature}). 
\\
Cepstral features (MFCCs) have been widely used for frog call classification, and have demonstrated high performance. However, cepstral features are found to be very sensitive to the background noise. This chapter proposes a novel cepstral feature using adaptive frequency scaled WPD. The scale is adaptively generated by applying k-means clustering to dominant frequencies of all the frog species to be classified. Compared to other frequency scales such as Mel-scale, the adaptive frequency scale can better reflect the frequency distribution of those frog species to be classified. Therefore, cepstral features calculated by adaptive frequency scaled WPD can capture more frequency information than Mel-scale.
Experimental results demonstrate that our proposed cepstral feature outperforms existing cepstral features that have been used for animal call classification.

\item[(3)]	Design a novel MIML framework to classify multiple simultaneously vocalising frog species in field recordings (Chapter \ref{cha:cha6MIML}).
\\
For frog call classification, almost all previous studies assume that one individual recording contains only one frog species. However, field recordings collected using acoustic sensors typically contain multiple frog species. This chapter proposes to use MIML learning to classify multiple simultaneously vocalising frog species with AED. A novel frog syllable segmentation method using AED is developed with limited annotated frog recordings. Compared to other AED methods, our proposed AED can achieve a better syllable segmentation results, which is reflected by the classification results. After segmentation, event-based features are independently computed from each syllable. Then, three MIML classifiers are used to classify multiple simultaneously vocalising frog species in field recordings. Compared to the non-informative classifier, our classification results for hamming loss is 2.7 times better. Experimental results show that our proposed MIML classification framework can achieve a better performance when compared to the SISL classification.


\item[(4)]	Design a novel ML framework to classify multiple simultaneously vocalising frog species in field recordings (Chapter \ref{cha:cha7ML}).
\\
The weakness of the MIML classification framework is that the classification performance is highly affected by AED results. However, current AED results cannot provide satisfied syllable segmentation results. To overcome this weakness, one solution is to prepare large volumes of annotated acoustic data and apply a supervised learning algorithm for improving the syllable segmentation results. Another is to use a different classification framework without the need of syllable segmentation. This chapter examines the latter option and proposes a ML classification framework to classify multiple simultaneously vocalising frog species in low SNR recordings. A novel feature construction method is proposed based on spectral clustering. A feature set of LPCs and AWSCCs is used for the ML classification. Experimental results show that ML classification can achieve similar performance with MIML classification, but has a better robustness of the classification results.



\end{enumerate}



\end{abstract}



%\newpage
%\begin{center}
%{\huge \textbf{List of Abbreviations}}
%\end{center}
%
%\begin{table}[htb!]
%%\caption{My caption}
%%\label{my-label}
%\begin{tabular}{lllll}
%DFT   &  &  &  & Discrete Fourier Transform          \\
%DCT   &  &  &  & Discrete Cosine Transform           \\
%SNR   &  &  &  & Signal to Noise Ratio               \\
%LPCs  &  &  &  & Linear Predictive Coding            \\
%MFCCs &  &  &  & Mel-Frequency Cepstral Coefficients \\
%LDA   &  &  &  & Linear Discriminant Analysis        \\
%K-NN  &  &  &  & K-Nearest Neighbour                 \\
%SVM   &  &  &  & Support Vector Machine              \\
%ANN   &  &  &  & Artificial Neural Network           \\
%RF    &  &  &  & Random Forest                       \\
%AED   &  &  &  & Acoustic Event Detection            \\
%WPD   &  &  &  & Wavelet Packet Decomposition        \\
%MIML  &  &  &  & Multiple-Instance Multiple-Label    \\
%ML    &  &  &  & Multiple Label                     
%\end{tabular}
%\end{table}



%============keywords
\begin{keywords}
Bioacoustics \\
Soundscape ecology\\
Field recording \\
Trophy recording\\
Frog call classification \\
Acoustic feature \\
Syllable segmentation\\
Wavelet packet decomposition \\
Multiple-instance multiple-label learning \\
Multiple-label learning \\
 
\end{keywords}






%============acknowledgement
\begin{ack}
First, I would like to express my sincere gratitude and thanks to Dr. Jinglan Zhang (principal supervisor), for giving me an opportunity to study in Australia. During the entirety of this PhD study, I have learnt so much from her about having passion for work, combined with high motivation, which will benefit me throughout my life. 
I would also like to express my gratitude to Prof. Paul Roe (associate supervisor), for his consistent instructions and financial supports through the last three years.  

I would also like to thank Dr. Michael Towsey (associate supervisor) for his provision of consistent guidance, discussions, and encouragement during my PhD study. Michael's attitude towards scientific research keeps motivating me go deeper into research.  


I want to thank Prof. Vinod Chandran (associate supervisor) for his support in writing my confirmation report and this thesis. Vinod's strong background knowledge in signal processing greatly helps me improve my understanding of this research.

I would also like to express my gratitude to my family, especially my grandparents, parents and my wife. They have always supported my overseas study. Without their support, I could not give my full attention to PhD study and  the completion of this thesis. 
My sincere thanks also go to all my friends for their love, attention and support to my PhD study. 

Finally, I extend my thanks to the China Scholarship Council (CSC), Queensland University of Technology, and Wet Tropics Management Authority for their financial support. 

\end{ack}


%=============preface
%\begin{preface}
%%Here is the preface. 
%%
%\end{preface}


%==============
% If you don't like to put nomenclature, which you have manually 
% edited in the file nomenclature.tex, at the front, comment the 
% following line out
% \listnomenclatureatfront{yes}{./nomenclature.tex} 

%==============
\afterpreface
