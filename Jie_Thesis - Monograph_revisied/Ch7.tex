% Ch5.tex

\chapter{Frog call classification based on multi-label learning}
\label{cha:cha7ML}
\textbf{Research problem}
\\
In Chapter \ref{cha:cha6MIML}, the classification performance is highly affected by the syllable segmentation results, which is realised by AED. 
\\
\textbf{Research sub-question}
\\
How to reduce the effect of AED results and classify multiple simultaneously vocalising frog species in low SNR recordings?


\section{Overview}
\label{sect:introduction}

This chapter describes the research conducted for classifying multiple simultaneously vocalising frog species. In Chapter \ref{cha:cha6MIML}, acoustic features are calculated based on AED results, and the MIML classification performance is highly affected by the accuracy of AED results. To reduce the bias introduced by AED, this chapter uses global feature sets for classifying multiple frog species in low-SNR recordings.
To be specific, three features are calculated: LPCs, MFCCs, and PWSCCs. Here, each feature is extracted from the whole 10-second recording without  syllable segmentation. Therefore, the classification process can be naturally framed as a ML learning framework.  



  



\section{Methods}

\subsection{Acquisition of frog call recordings}

To evaluate the proposed algorithm, the same dataset with Chapter~\ref{cha:cha6MIML} is used. The description of this dataset can be found in Chapter~\ref{chap5:Materials}. We first manually inspect spectrograms of ten randomly selected call examples for each frog species. Two parameters, dominant frequency and syllable duration, are measured and averaged, as listed in Table~\ref{tab:Ch7_parameters}, which are used as prior information for subsequent analysis.



\subsection{Feature extraction}
Extracting discriminating features, which maximise between-group (inter-specie) dissimilarity
and minimise within-group (intra-specie) dissimilarity, is very important for achieving high classification performance \citep{huang2009frog, bedoya2014automatic}. In this chapter, three global features are calculated to classify multiple simultaneously vocalising frog species in each 10-second recording: LPCs, MFCCs, and PWSCCs. 





\textit{LPCs}
Linear prediction coding (LPCs) is often used to represent the spectral envelope of speech sounds \citep{itakura1975line}. LPCs coefficients can be calculated using a linear predictive filter.

\begin{equation}
X(n) = \sum_{i}^{p}a_{i}x(n-i)
\end{equation}
where $p$ is the order of the polynomial $a_{i}$. In the proposed study, the value of $p$ is set at 12 (12th-order polynomial), and 13 LPCs coefficients are calculated. For those frog vocalizations with different spectral envelopes, LPCs can obtain a high classification accuracy, and has been widely used in previous studies \cite{yuan2012frog, jaafarcomparative, jaafar2015effect}.

\textit{MFCC}
The description for calculating MFCCs can be found in Chapter~\ref{cha:cha4EnhancedFeature}. The difference is that each 10-second recording is first split into frames using a Hamming window. Then, all frames are divided into three equal parts, and MFCCs is averaged over each part. Finally, MFCCs of each part are concatenated into a final feature named as \textit{multi-stage MFCCs}. The reason for dividing the recording into three equal parts is to keep the information of different frog species in the same frequency band, 
because different frog species may exist in different temporal locations of one 10-second recording. 


\textit{PWSCCs}
To calculate PWSCCs, constructing a suitable frequency scale for a WP tree based on the dominant frequency of each frog species is the first step, because different frog species tend to have different dominant frequencies \citep{Gingras2013}. In Chapter \ref{cha:cha5WaveletFeature}, k-means clustering was first applied to the extracted dominant frequencies of training data. Then, the frequency scale was built by sorting clustering centroids to construct the WP tree. In this chapter, the prior information for dominant frequency ($F_{0}$) (Table~\ref{tab:Ch7_parameters}) is directly used to construct the WP tree. Then, the steps for calculating PWSCCs are the same with Chapter~\ref{cha:cha5WaveletFeature}. Similar with MFCCs, PWSCCs are also calculated by dividing the recording into three equal parts. The final feature is named as \textit{multi-stage PWSCCs}.

\subsection{Feature construction}

Cepstral features are calculated of each frame. Then, two methods are used to construct the final feature set.




\subsection{Multi-label classification} 
Since many sampled recordings consist of calls from multiple frog species, frog call classification can be framed as a ML learning problem. However, previous studies have not adopted ML learning to classify frog calls. Therefore, it is worth investigating different ML learning algorithms for the classification of multiple vocalising frog species in low SNR recordings. for its scalability and flexibility \citep{read2011classifier}. The principle of the BR method is to solve a multi-label classification problem using multiple binary classifiers respectively. Similar to our previous work \citep{zhang2016using}, 
three classic single-label learning algorithms: decision tree, and multi-layer perceptron, and random forest. Here, random forest is selected as the base classifier, since our previous study of classifying frog species has already demonstrated its comparable performance \citep{xie2016acoustic}. 

\section{Experiment results}
Each 10-second recording is divided into frames of 512 samples and 50\% frame overlap for STFT. For MFCCs and PWSCCs, window size and overlap are 512 samples and 50\%, the window function is a Hamming window. All algorithms were programmed in Matlab 2014b except ML learning, which was implemented in Meka 1.7.7\footnote[4]{http://meka.sourceforge.net/}. 







\subsection{Evaluation metrics}
For multi-label classification, the performance evaluation differs from the classic single-label classification systems. The multi-label classification results often have a situation where partial labels are correctly predicted, but the prediction of single-label classification is either correct or incorrect. Therefore, some traditional evaluation metrics for the single-label classification, such as precision, recall, and accuracy, are no longer suitable for the multi-label classification system. In this study, three evaluation metrics, hamming loss, accuracy, and subset accuracy, are used, where all the three are example based measures \citep{madjarov2012extensive}.


The definition of Hamming loss can be found in Chapter~\ref{cha:cha6MIML}.
%Hamming loss is defined as the fraction of labels that are incorrectly predicted for an instance and the normalised hamming loss which is normalised over instances is reported. This metric is defined as
%\begin{equation}
%hammingLoss = \frac{1}{N}\sum_{i=1}^{N}\frac{1}{Q}|h(x_{i})\Delta y_{i})|
%\end{equation}
%where $\Delta$ denotes the symmetric difference between two instances,  and $Q$ is the total number of possible labels. 

Accuracy for a single instance $x_{i}$ is defined by the Jaccard similarity coefficients between the ground truth $y_{i}$ and the prediction $h(x_{i})$. Accuracy is micro-averaged across all examples:

\begin{equation}
accuracy = \frac{1}{N}\sum_{i=1}^{N}|\frac{h(x_{i} \cap y_{i})}{h(x_{i} \cup y_{i}}|
\end{equation}
where $N$ is the number of instances, $y_{i}$ denotes the ground truth of instance $x_{i}$, and $h(x_{i})$ denotes the predictions for the same instance. 


Subset accuracy is defined as follows:
\begin{equation}
subsetAccuracy = \frac{1}{N}\sum_{i=1}^{N}I(h(x_{i})=y_{i})
\end{equation}
where $I(true)=1$ and $I(false)=0$. This is a very strict evaluation
measure as it requires the predicted set of labels to be an exact
match of the true set of labels.


The values for hamming loss, accuracy, and subset accuracy range from 0 to 1. For hamming loss, 0 denotes the perfect result, and 1 means the wrong prediction of all labels over every instance, whereas for accuracy and subset accuracy, the values have the completely opposite meanings.



\subsection{Classification results}

Experiment results are shown in Table~\ref{tab:classificationResults}. The combination of LPCs, MFCCs, and PWSCCs, can achieve the best performance with ML-MLP. 



\begin{table}[htb!]
\centering
\caption{Comparison of different feature sets for ML classification}
\label{tab:classificationResults}
\resizebox{\textwidth}{!}{
\begin{tabular}{lllll}
\hline\hline
Feature set           & Classifier                             & Hamming loss & Accuracy    & Subset accuracy \\ \hline
MFCCs                 & \multirow{4}{*}{Multilayer Perceptron} & 0.155 $\pm$ 0.019  & 0.613 $\pm$ 0.059 & 0.292 $\pm$ 0.071     \\ \cline{1-1} \cline{3-5} 
PWSCCs                &                                        & 0.143 $\pm$ 0.013  & 0.661 $\pm$ 0.013 & 0.374 $\pm$ 0.017     \\ \cline{1-1} \cline{3-5} 
MFCCs + PWSCCs        &                                        & 0.125 $\pm$ 0.007  & 0.702 $\pm$ 0.029 & 0.403 $\pm$ 0.051     \\ \cline{1-1} \cline{3-5} 
MFCCs + PWSCCs + LPCs &                                        & 0.111 $\pm$ 0.009  & 0.727 $\pm$ 0.017 & 0.444 $\pm$ 0.028     \\ \hline\hline
\end{tabular}
}
\end{table}




\begin{table}[htb!]
\centering
\caption{Comparison of different ML classifiers}
\label{my-label}
\resizebox{\textwidth}{!}{
\begin{tabular}{lllll}
\hline\hline
Feature set           & Classifier            & Hamming loss & Accuracy    & Subset accuracy \\ \hline
MFCCs + PWSCCs + LPCs & ML-kNN                   & 0.137 $\pm$ 0.013  & 0.698 $\pm$ 0.027 & 0.397 $\pm$ 0.066     \\ 
MFCCs + PWSCCs + LPCs & ML-Decision Tree         & 0.155 $\pm$ 0.011  & 0.608 $\pm$ 0.037 & 0.263 $\pm$ 0.049     \\ 
MFCCs + PWSCCs + LPCs & ML-Multilayer Perceptron & 0.111 $\pm$ 0.009  & 0.727 $\pm$ 0.017 & 0.444 $\pm$ 0.028     \\ \hline\hline
\end{tabular}
}
\end{table}




\subsection{Comparison with MIML}
In this chapter, ML learning is used to classify frog calls without syllable segmentation. Compared with the MIML learning (Figure~\ref{fig:classificationResults} in Chapter~\ref{cha:cha6MIML}), the ML classification has a slightly better classification performance. For ML classification, LPCs, MFCCs, and PWSCCs are combined for the classification. MFCCs and PWSCCs are calculated by averaging cepstral features in the temporal direction. Although this process will compress the information in the temporal direction, the information of the cepstral domain is obtained. Since most frog species tend to continuously make calls, the compression of the temporal information will not greatly affect the discriminability of the ceptral features.
LPCs are added to get the temporal information. In contrast, features used for MIML classification are calculated from each segmented syllable. However, current AED often cannot accurately segment frog calls with low energies, which greatly affects the classification performance.




\section{Summary and limitations}
In this chapter, ML learning is used to classify multiple simultaneously vocalising frog species in low SNR recordings. Three global feature are combined together for the classification: LPCs, MFCCs, and PWSCCs. For the ML classification, three classifiers are compared: ML-kNN, ML-DT, and ML-MLP. ML-MLP can achieve the best classification performance over ML-kNN and ML-DT.






%Acoustic sensors are more widely used to monitor frog calling activity and species richness than the traditional field survey method. However, the use of acoustic sensors generates large volumes of audio data, which makes it necessary to develop automated methods. This paper proposes a novel method for detecting frog calling activity and species richness based on AED and ML learning. Specifically,
%AED is the first step to calculate frog calling activity. Meanwhile, those 10-second recordings without frog calls are filtered out. For those recordings with frog calls, ML learning is further used for estimating frog species richness with multi-stage PWSCCs and LPCs. Finally, statistical analysis is utilised to reflect the relationship between frog calling activity/species richness with weather variables (mean temperature and rainfall). Experimental results show that our proposed method can accurately estimate frog calling activity/species richness and reflect their relationship with weather variables. Future work will focus on a wider frog call database, including a larger number of frog species, and frog calls collected over a longer period.


