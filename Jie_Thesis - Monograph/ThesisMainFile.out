\BOOKMARK [0][-]{chapter*.3}{Abstract}{}% 1
\BOOKMARK [0][-]{chapter*.4}{Keywords}{}% 2
\BOOKMARK [0][-]{chapter*.5}{Acknowledgments}{}% 3
\BOOKMARK [0][-]{chapter*.7}{List of Figures}{}% 4
\BOOKMARK [0][-]{chapter*.8}{List of Tables}{}% 5
\BOOKMARK [0][-]{chapter*.9}{Nomenclature}{}% 6
\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 7
\BOOKMARK [1][-]{section.1.1}{Motivation and background}{chapter.1}% 8
\BOOKMARK [1][-]{section.1.2}{Basic concepts}{chapter.1}% 9
\BOOKMARK [2][-]{subsection.1.2.1}{Environment audio data}{section.1.2}% 10
\BOOKMARK [2][-]{subsection.1.2.2}{Audio data analysis}{section.1.2}% 11
\BOOKMARK [2][-]{subsection.1.2.3}{Frog call structure}{section.1.2}% 12
\BOOKMARK [2][-]{subsection.1.2.4}{Acoustic event and background noise}{section.1.2}% 13
\BOOKMARK [2][-]{subsection.1.2.5}{Frog call classification}{section.1.2}% 14
\BOOKMARK [2][-]{subsection.1.2.6}{Research problem}{section.1.2}% 15
\BOOKMARK [2][-]{subsection.1.2.7}{Research questions}{section.1.2}% 16
\BOOKMARK [2][-]{subsection.1.2.8}{Aims and objectives}{section.1.2}% 17
\BOOKMARK [2][-]{subsection.1.2.9}{Significance and contributions}{section.1.2}% 18
\BOOKMARK [2][-]{subsection.1.2.10}{Thesis structure}{section.1.2}% 19
\BOOKMARK [0][-]{chapter.2}{Literature Review}{}% 20
\BOOKMARK [1][-]{section.2.1}{Introduction}{chapter.2}% 21
\BOOKMARK [1][-]{section.2.2}{Signal pre-processing}{chapter.2}% 22
\BOOKMARK [2][-]{subsection.2.2.1}{Signal processing}{section.2.2}% 23
\BOOKMARK [2][-]{subsection.2.2.2}{Noise reduction}{section.2.2}% 24
\BOOKMARK [2][-]{subsection.2.2.3}{Syllable segmentation}{section.2.2}% 25
\BOOKMARK [1][-]{section.2.3}{Acoustic features for frog call classification}{chapter.2}% 26
\BOOKMARK [2][-]{subsection.2.3.1}{Time domain and frequency domain features for frog call classification}{section.2.3}% 27
\BOOKMARK [2][-]{subsection.2.3.2}{Time-frequency features for frog call classification}{section.2.3}% 28
\BOOKMARK [2][-]{subsection.2.3.3}{Cepstral features for frog call classification}{section.2.3}% 29
\BOOKMARK [2][-]{subsection.2.3.4}{Other features for frog call classification}{section.2.3}% 30
\BOOKMARK [1][-]{section.2.4}{Classifiers}{chapter.2}% 31
\BOOKMARK [1][-]{section.2.5}{Experiment results of the state-of-the-art methods}{chapter.2}% 32
\BOOKMARK [2][-]{subsection.2.5.1}{Evaluation criteria}{section.2.5}% 33
\BOOKMARK [2][-]{subsection.2.5.2}{Experiment results for summarise}{section.2.5}% 34
\BOOKMARK [1][-]{section.2.6}{Discussion and future work}{chapter.2}% 35
\BOOKMARK [2][-]{subsection.2.6.1}{Database}{section.2.6}% 36
\BOOKMARK [2][-]{subsection.2.6.2}{Signal pre-processing}{section.2.6}% 37
\BOOKMARK [2][-]{subsection.2.6.3}{Acoustic features}{section.2.6}% 38
\BOOKMARK [2][-]{subsection.2.6.4}{Classifiers}{section.2.6}% 39
\BOOKMARK [1][-]{section.2.7}{Conclusions}{chapter.2}% 40
\BOOKMARK [0][-]{chapter.3}{Frog call classification based on enhanced features and machine learning algorithms}{}% 41
\BOOKMARK [1][-]{section.3.1}{Introduction}{chapter.3}% 42
\BOOKMARK [1][-]{section.3.2}{Architecture of the classification system for frog calls}{chapter.3}% 43
\BOOKMARK [2][-]{subsection.3.2.1}{Data description}{section.3.2}% 44
\BOOKMARK [2][-]{subsection.3.2.2}{Syllable segmentation based on an adaptive end point detection}{section.3.2}% 45
\BOOKMARK [2][-]{subsection.3.2.3}{Pre-processing}{section.3.2}% 46
\BOOKMARK [2][-]{subsection.3.2.4}{Feature extraction}{section.3.2}% 47
\BOOKMARK [2][-]{subsection.3.2.5}{Classifier description}{section.3.2}% 48
\BOOKMARK [1][-]{section.3.3}{Experiment results}{chapter.3}% 49
\BOOKMARK [2][-]{subsection.3.3.1}{Effects of different machine learning techniques}{section.3.3}% 50
\BOOKMARK [1][-]{section.3.4}{Discussion}{chapter.3}% 51
\BOOKMARK [1][-]{section.3.5}{Conclusion and future work}{chapter.3}% 52
\BOOKMARK [0][-]{chapter.4}{Adaptive frequency scaled wavelet packet decomposition for frog call classification}{}% 53
\BOOKMARK [1][-]{section.4.1}{Introduction}{chapter.4}% 54
\BOOKMARK [1][-]{section.4.2}{Methods}{chapter.4}% 55
\BOOKMARK [2][-]{subsection.4.2.1}{Sound recording and pre-processing}{section.4.2}% 56
\BOOKMARK [2][-]{subsection.4.2.2}{Spectrogram analysis based on validation set}{section.4.2}% 57
\BOOKMARK [2][-]{subsection.4.2.3}{Syllable segmentation}{section.4.2}% 58
\BOOKMARK [2][-]{subsection.4.2.4}{Spectral peak track extraction}{section.4.2}% 59
\BOOKMARK [2][-]{subsection.4.2.5}{Syllable SPT features}{section.4.2}% 60
\BOOKMARK [2][-]{subsection.4.2.6}{Wavelet packet decomposition}{section.4.2}% 61
\BOOKMARK [2][-]{subsection.4.2.7}{WPD based on an adaptive frequency scale}{section.4.2}% 62
\BOOKMARK [2][-]{subsection.4.2.8}{Feature extraction based on adaptive frequency scaled WPD}{section.4.2}% 63
\BOOKMARK [2][-]{subsection.4.2.9}{Classification}{section.4.2}% 64
\BOOKMARK [1][-]{section.4.3}{Experiment result and discussion}{chapter.4}% 65
\BOOKMARK [2][-]{subsection.4.3.1}{Parameter tuning}{section.4.3}% 66
\BOOKMARK [2][-]{subsection.4.3.2}{Feature evaluation}{section.4.3}% 67
\BOOKMARK [2][-]{subsection.4.3.3}{Comparison between different feature sets}{section.4.3}% 68
\BOOKMARK [2][-]{subsection.4.3.4}{Comparison under different SNRs}{section.4.3}% 69
\BOOKMARK [2][-]{subsection.4.3.5}{Proposed feature evaluation using the JCU recordings}{section.4.3}% 70
\BOOKMARK [1][-]{section.4.4}{Conclusion and future work}{chapter.4}% 71
\BOOKMARK [0][-]{chapter.5}{Multiple-instance multiple-label learning for the classification of frog calls with acoustic event detection}{}% 72
\BOOKMARK [1][-]{section.5.1}{Introduction}{chapter.5}% 73
\BOOKMARK [1][-]{section.5.2}{Materials and methods}{chapter.5}% 74
\BOOKMARK [2][-]{subsection.5.2.1}{Materials}{section.5.2}% 75
\BOOKMARK [2][-]{subsection.5.2.2}{Signal processing}{section.5.2}% 76
\BOOKMARK [2][-]{subsection.5.2.3}{Acoustic event detection for syllable segmentation}{section.5.2}% 77
\BOOKMARK [2][-]{subsection.5.2.4}{Feature extraction}{section.5.2}% 78
\BOOKMARK [1][-]{section.5.3}{Multiple-instance multiple-label classifiers}{chapter.5}% 79
\BOOKMARK [1][-]{section.5.4}{Experiment results}{chapter.5}% 80
\BOOKMARK [2][-]{subsection.5.4.1}{Parameter tuning}{section.5.4}% 81
\BOOKMARK [2][-]{subsection.5.4.2}{Classification}{section.5.4}% 82
\BOOKMARK [1][-]{section.5.5}{Conclusion}{chapter.5}% 83
\BOOKMARK [0][-]{chapter.6}{Detecting frog calling activity based on acoustic event detection and multi-label learning}{}% 84
\BOOKMARK [1][-]{section.6.1}{Introduction}{chapter.6}% 85
\BOOKMARK [1][-]{section.6.2}{Materials and methods}{chapter.6}% 86
\BOOKMARK [2][-]{subsection.6.2.1}{Acquisition of frog call recordings}{section.6.2}% 87
\BOOKMARK [2][-]{subsection.6.2.2}{Frog abundance monitoring}{section.6.2}% 88
\BOOKMARK [2][-]{subsection.6.2.3}{Wavelet-based feature extraction for species richness analysis}{section.6.2}% 89
\BOOKMARK [2][-]{subsection.6.2.4}{Multi-label classification for species richness analysis}{section.6.2}% 90
\BOOKMARK [1][-]{section.6.3}{Experiment setup}{chapter.6}% 91
\BOOKMARK [1][-]{section.6.4}{Experiment results}{chapter.6}% 92
\BOOKMARK [2][-]{subsection.6.4.1}{Frog abundance detection}{section.6.4}% 93
\BOOKMARK [2][-]{subsection.6.4.2}{Frog species richness analysis}{section.6.4}% 94
\BOOKMARK [2][-]{subsection.6.4.3}{Statistical analysis}{section.6.4}% 95
\BOOKMARK [1][-]{section.6.5}{Conclusion and future work}{chapter.6}% 96
\BOOKMARK [0][-]{chapter.7}{Conclusions and Future work}{}% 97
\BOOKMARK [1][-]{section.7.1}{Summary of contributions}{chapter.7}% 98
\BOOKMARK [1][-]{section.7.2}{Limitations and further research}{chapter.7}% 99
\BOOKMARK [0][-]{appendix.H}{Frog species studied in this study}{}% 100
\BOOKMARK [0][-]{appendix*.83}{Literature Cited}{}% 101
